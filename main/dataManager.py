import openai
from pinecone import Pinecone
from google.cloud import translate_v2 as translate

from dotenv import load_dotenv, find_dotenv
import os

from datetime import datetime
import json


class Manager_model():
    """
    The Manager_model class is used for the following purposes:
    - Adding job descriptions to the database.
    - Adding candidates to the database.
    - Deleting candidates from the database.
    - Deleting job descriptions from the database.

    The flow of each of the above functionalities is as follows:

    1. Adding job descriptions to the database:
                            a. The raw data of the job description is taken as input.
                                                    |
                    b. The title, desciption and skills is used to create the system and user prompts.
                                                    |
                        c. OpenAI 'gp3-5-turbo' is used to get a precise and concise description
                                                    |
                                d. The description is converted to embeddings
                                                    |
                            e. The embeddings are upserted to the Pinecone database
                                                    |
                            f. A final description of the job description is returned

    2. Adding candidates to the database:
        The raw data of the candidate is taken as input and all the projects of the candidate are looped through steps a-d in the above process.

        Following this, all the project descriptions are combined to get the combined description of all the projects of the candidate.

        The individual project descriptions and the combined description of all the projects of the candidate are converted to embeddings and upserted to the Pinecone database.

        A final description of the candidate is returned.

    3. Deleting candidates from the database:
        The raw data of the candidate is taken as input.
        All project names are extracted and combined with cadidate's id to get the vector ids to be deleted.
        The project vector ids are deleted from the Pinecone database.
        The final description of the candidate is deleted from the Pinecone database.

    4. Deleting job descriptions from the database:
        The raw data of the job description is taken as input.
        The vector id of the job description is deleted from the Pinecone database.
    ...

    Attributes
    ----------
    data : dict
        A dictionary containing the raw data of the candidate or the job description.

    __client : openai.OpenAI
        An instance of the OpenAI class.

    __pc : Pinecone
        An instance of the Pinecone class.

    __max_experience_days : int
        The maximum experience a candidate is allowed to have (in days).

    __pinecone_config : dict
        A dictionary containing the configuration of the Pinecone database.

    Methods
    -------
    __translate_ja_en(description)
        Translates a text (in any language) to English using the Google Cloud Translate API.

    __create_jdk_prompt(title, description, skills)
        Creates the system and user prompts to be used for getting the final description of the job description.

    __create_candidate_prompt(title, description, skills)
        Creates the system and user prompts to be used for getting the final description of a candidate's project.

    __get_gpt_description(system_prompt, user_prompt)
        Feeds the system and user prompts to the OpenAI 'gpt-3.5-turbo' and returns the output generated by the model.

    __create_openai_embeddings(description_list)
        Creates vector embeddings for the given list of descriptions using the OpenAI 'text-embedding-ada-002' model.

    __upsert_to_database(namespace, embeddings_vector)
        Upserts the given vector to the Pinecone database under the given namespace.

    __get_jdk_final_description(title, description, skills)
        Takes the title, gpt generated description, and skills of the job description and returns the final description of the job description to be stored in the database.

    __get_cand_combined_desc(titles, final_descriptions, skill_info)
        Returns the combined description of all the projects of the candidate.

    __get_experience(start_date, end_date)
        Returns the experience of the candidate in months.

    add_jdk(data)
        Adds a job description to the database.

    add_candidate(data)
        Adds a candidate to the database.

    delete_candidate(data)
        Deletes the candidate from the database.

    delete_jdk(data)
        Deletes the job description from the database.    
    """

    def __init__(self):
        """
        Constructs all the necessary attributes for the Manager_model object.

        Parameters
        ----------
        None
        """

        # Load .env file
        _ = load_dotenv(find_dotenv())

        # Set the OpenAI API key and create an instance of the OpenAI class
        openai.api_key = os.environ.get("OPENAI_API_KEY")
        self.__client = openai.OpenAI()

        # Create an instance of the Pinecone class
        pinecone_key = os.environ.get('PINECONE_API_KEY')
        self.__pc = Pinecone(
            api_key=pinecone_key,
            environment='gcp-starter'
        )

        # Load the configuration file
        config = json.load(open('./config.json'))

        # Extract the maximum experience a candidate is allowed to have (in days) from the configuration file
        self.__max_experience_days = config['experience_params']['maximum_experience'] * 30

        # Extract the Pinecone database configuration from the configuration file
        self.__pinecone_config = config['pinecone_config']

    def __translate_ja_en(self, description):
        """
        Translates a text (in any language) to English using the Google Cloud Translate API.

        Parameters:
        ----------
        description : str
            The text to be translated.

        Returns:
        -------
        str:
            The translated text in English.
        """

        # Set the environment variable for the Google Cloud credentials
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = r"../google-credentials.json"

        # Create an instance of the Google Cloud Translate API
        translate_client = translate.Client()

        # Translate the given text to English and get the translated text
        target = "en"               # Set the target language to English
        output = translate_client.translate(description, target_language=target)[
            'translatedText']

        return output

    def __create_jdk_prompt(self, title, description, skills):
        """
        Creates the system and user prompts to be used for getting the final description of the job description.

        Parameters
        ----------
        title : str
            The title of the job description.
        description : str
            The description of the job description.
        skills : str
            The skills required for the job.

        Returns
        -------
        tuple[str, str]:
            A tuple containing the system prompt and the user prompt respectively.
        """

        # System Prompt
        system_prompt = """You are a summarizing agent who takes job descriptions and converts them into concise and precise two line descriptions."""

        # User Prompt
        user_prompt = f"""We have jobs to offer to interested people. Each job has a title, a job description, and the skills required for that job. To help people understand the job position in a better manner, your task is to combine all these three separate things to create a concise and more precise description of the job. Remove irrelevant information from the job description and only include the important information that will help people understand the job position better.

        Job Title: {title}
        Job Description: {description}
        Skills Required: {skills}
        """

        return system_prompt, user_prompt

    def __create_candidate_prompt(self, title, description, skills):
        """
        Creates the system and user prompts to be used for getting the final description of a candidate's project.

        Parameters
        ----------
        title : str
            The title of the candidate's project.
        description : str
            The description of the candidate's project.
        skills : str
            The skills used in the candidate's project.

        Returns
        -------
        tuple[str, str]:
            A tuple containing the system prompt and the user prompt respectively.
        """

        # System Prompt
        system_prompt = """You are a summarizing agent who takes project descriptions and converts them into a more concise and precise two line descriptions."""

        # User Prompt
        user_prompt = f"""All the candidates who have applied for jobs have submiited their resumes. All resumes contain the details about the projects that the candidate has worked on. Each project has a title, a description, and the skills that were put to use to complete that project. Your task is to combine all these three separate things to create a concise and more precise description of the project. Remove irrelevant information from the project description and only include the important information that will be relevant when applying for a job.

        Project Title: {title}
        Project Description: {description}
        Skills Used: {skills}
        """

        return system_prompt, user_prompt

    def __get_gpt_description(self, system_prompt, user_prompt):
        """
        This function feeds the system and user prompts to the OpenAI 'gpt-3.5-turbo' and returns the output generated by the model.
        It is used to get the final (precise and concise) summary of the job description or the candidate's project.

        This descriptions will be used to create embeddings for the job description or the candidate's project.

        Parameters
        ----------
        system_prompt : str
            The system prompt to be fed to the model.
        user_prompt : str
            The user prompt to be fed to the model.

        Returns
        -------
        str
            A precise and concise summary of the job description or the candidate's project.
        """

        # Set the model to 'gpt-3.5-turbo' and create a list of messages containing the system and user prompts
        model = "gpt-3.5-turbo"
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        # Get the description from the OpenAI 'gpt-3.5-turbo' model using the chat completions API endpoint
        response = self.__client.chat.completions.create(
            model=model,
            messages=messages
        )

        # Get the generated description from the response object
        gpt_description = response.choices[0].message.content

        return gpt_description

    def __create_openai_embeddings(self, description_list):
        """
        This function creates vector embeddings for the given list of descriptions using the OpenAI 'text-embedding-ada-002' model.

        When jdk is being added, the description_list will contain only one description.

        When a candidate is being added, the description_list will contain the descriptions of all the projects of the candidate.

        Parameters
        ----------
        description_list : list
            A list of descriptions for which the embeddings have to be created.

        Returns
        -------
        list
            A list of embeddings for the given list of descriptions.
        """

        # Set the model to 'text-embedding-ada-002'
        model = "text-embedding-ada-002"

        # Call the OpeanAI endpoint to get the embeddings for the given list of descriptions
        response = self.__client.embeddings.create(
            input=description_list, model=model).data
        # Extract the embeddings list from the response object
        embeddings = [element.embedding for element in response]

        return embeddings

    def __upsert_to_database(self, namespace, embeddings_vector):
        """
        This function upserts the given vector to the Pinecone database under the given namespace.

        Parameters
        ----------
        namespace : str
            The namespace to which the vector has to be upserted.
        embeddings_vector : list
            The vector to be upserted.

        Returns
        -------
        None     
        """

        # Set the index name
        index_name = self.__pinecone_config['index_name']
        # Create an instance of the Pinecone Index
        index = self.__pc.Index(index_name)

        # Upsert the vector to the Pinecone database under the given namespace
        index.upsert(
            vectors=embeddings_vector,
            namespace=namespace
        )

        return

    def __get_jdk_final_description(self, title, description, skills):
        """
        Takes the title, gpt generated description, and skills of the job description and returns the final description of the job description to be stored in the database.

        This description will later be used for reasoning the scores during the matching process.

        Parameters
        ----------
        title : str
            The title of the job description.
        description : str
            The description of the job description.
        skills : str
            The skills required for the job.

        Returns
        -------
        str
            The final description of the job description.
        """

        # Combine the title, gpt generated description, and skills of the job description to get the final description
        description = f"The title of the job is '{title}'. {description}" + \
            f"SKILLS: {skills}"

        return description

    def add_jdk(self, data):
        """
        This function can be called to add a job description to the database.

        It takes the raw data of the job description and:
        1. creates the system and user prompts,
        2. gets the final description of the job description using the OpenAI 'gpt-3.5-turbo' model,
        3. creates the embeddings for the final description, and
        4. upserts the embeddings to the Pinecone database.

        And it returns the final description of the job description.

        Parameters
        ----------
        data : dict
            A dictionary containing the raw data of the job description.
            The dictionary should contain the following
            - id (str): The unique identifier of the job description.
            - title (str): The title of the job description.
            - description (str): The description of the job description.
            - skills (list): The skills required for the job description.

        Returns
        -------
        str
            The final description created from the job description.
        """

        # Set the raw data of the job description
        self.data = data

        # Extract the id, title, description, and skills from the raw data
        jdk_id = self.data['id']
        title = self.data['title']
        description = self.data['description']
        skills = self.data['skills']
        # Convert the list of skills to a string
        skills = ", ".join(skills)

        # Translate the description to English
        description = self.__translate_ja_en(description)

        # Create the system and user prompts
        system_prompt, user_prompt = self.__create_jdk_prompt(
            title, description, skills)

        # Get the final description of the job description using the OpenAI 'gpt-3.5-turbo' model
        gpt_description = self.__get_gpt_description(
            system_prompt, user_prompt)

        # Get the embeddings for the final description
        embeddings = self.__create_openai_embeddings([gpt_description])
        # Extract the embeddings from the list, as it contains only one element
        description_embeddings = embeddings[0]

        # Get the namespace from the Pinecone configuration
        jdk_namespace = self.__pinecone_config['jdk_namespace']
        # Create the vector to be upserted to the database
        vector = [{"id": str(jdk_id), "values": description_embeddings, "metadata": {
            "jdk_id": str(jdk_id)}}]

        # Upsert the vector to the Pinecone database
        self.__upsert_to_database(jdk_namespace, vector)

        # Get the final description of the job description
        final_description = self.__get_jdk_final_description(
            title, gpt_description, skills)

        return final_description

    def __get_cand_combined_desc(self, titles, final_descriptions, skill_info):
        """
        Returns the combined description of all the projects of the candidate.

        Parameters
        ----------
        titles : list
            The list of titles of the candidate's projects.
        final_descriptions : list
            The list of descriptions of the candidate's projects.
        skill_info : list
            The list of skills used in the candidate's projects.

        Returns
        -------
        str
            The combined description of all the projects of the candidate.
        """

        # Initialize the combined description of all the projects
        all_project_desc = ""

        # Combine the title, description, and skills of each project to get the combined description
        for title, description, skills in zip(titles, final_descriptions, skill_info):
            all_project_desc += f"The project is titled '{title}'. {description}" + \
                f"The project uses {skills}. "

        return all_project_desc

    def __get_experience(self, start_date, end_date):
        """
        Returns the experience of the candidate in months.

        Uses datetime to calculate the difference between the start and end dates of the candidate's project.

        The maximum experience a candidate is allowed to have is set in the configuration file.

        The experience counting is taking intervals of 15 days. (i.e. 10 days will be counted as 0.5 months, 20 days will be counted as 1 month, and so on.)

        But, 0.5 months is returned as 1. 1 month is returned as 2. And so on.
        This is done to to store integer values in the pinecone database.

        Parameters
        ----------
        start_date : str
            The start date of the candidate's project.
        end_date : str
            The end date of the candidate's project.

        Returns
        -------
        int
            The experience of the candidate in months.
        """

        # Defines the date format (as per the input date format in the raw data)
        date_format = "%d/%m/%Y"

        # Convert the start and end dates to datetime objects
        end_date_obj = datetime.strptime(end_date, date_format).date()
        start_date_obj = datetime.strptime(start_date, date_format).date()

        # Calculate the difference between the start and end dates
        exp_diff = end_date_obj - start_date_obj

        # Limit the experience to the maximum experience allowed and then convert it to months
        experience = min(exp_diff.days, self.__max_experience_days)
        experience = int(round(experience/15, 0))

        return experience

    def add_candidate(self, data):
        """
        This function can be called to add a candidate to the database.

        It takes the raw data of the candidate and loops through the candidate's projects to one by one:
        1. create the system and user prompts,
        2. get the final description of the candidate's project using the OpenAI 'gpt-3.5-turbo' model,
        3. create the embeddings for the final description, and
        4. upsert the embeddings to the Pinecone database.

        And it returns the combined description of all the projects of the candidate.

        Parameters
        ----------
        data : dict
            A dictionary containing the raw data of the candidate.
            The dictionary should contain the following
            - id (str): The unique identifier of the candidate.
            - projects (list): The list of projects of the candidate. Each project should contain the following
                - title (str): The title of the project.
                - description (str): The description of the project.
                - skills (list): The skills used in the project.
                - startDate (str): The start date of the project.
                - endDate (str): The end date of the project.

        Returns
        -------
        str
            The combined description of all the projects of the candidate.
        """

        # Set the raw data of the candidate
        self.data = data

        # Extract the id and projects info from the raw data
        candidate_id = self.data['id']
        projects = self.data['projects']

        # Initialize the lists to store the titles, descriptions, and skills of the candidate's projects and the metadata of each project
        pinecone_titles = []
        titles = []
        final_descriptions = []
        skill_info = []
        metadatas = []

        # Initialize the set to store the unique skills of the candidate (taken from all the projects of the candidate)
        unique_skills = set()

        # Loop through the projects of the candidate
        for project in projects:
            # Extract the title, description, skills, start date, and end date of the project
            title = project['title']
            description = project['description']
            skills = project['skills']
            unique_skills.update(skills)
            skills = ", ".join(skills)

            end_date = project['endDate']
            start_date = project['startDate']

            # Get the experience on the project in months
            experience = self.__get_experience(start_date, end_date)

            # Create the title which will correspond to the project's vector in the Pinecone database
            # The title is a combination of the candidate's id and the title of the project
            vec_title = f"{candidate_id}__{title}"
            pinecone_titles.append(vec_title)

            # Append the title and the skills of the project to the titles and skill_info lists respectively
            titles.append(f"{title}")
            skill_info.append(skills)

            # Get the system and user prompts for the project
            system_prompt, user_prompt = self.__create_candidate_prompt(
                title, description, skills)

            # Get the gp3 generated description for the project and append it to the final_descriptions list
            gpt_description = self.__get_gpt_description(
                system_prompt, user_prompt)
            final_descriptions.append(gpt_description)

            # Append the metadata of the project to the metadatas list
            # Metadata contains the following: 1. candidate_id, 2. experience
            metadatas.append(
                {"candidate_id": f'{candidate_id}', 'experience': experience})

        # Get the combined description of all the projects of the candidate
        all_projects_desc = self.__get_cand_combined_desc(
            titles, final_descriptions, skill_info)

        # Add the unique skills of the candidate to the combined description to create the final description of the candidate
        cand_final_desc = f"The candidate has worked on the following projects: {all_projects_desc}" + \
            f"SKILLS:  {', '.join(unique_skills)}."

        # Append the final description of the candidate to the final_descriptions list and create the embeddings for the final descriptions
        final_descriptions.append(cand_final_desc)
        embeddings = self.__create_openai_embeddings(final_descriptions)

        # UPSERTING THE INDIVIDUAL PROJECTS TO THE DATABASE
        # Extract the namespace from the Pinecone configuration
        namespace = self.__pinecone_config['projects_namespace']
        # Create the vector to be upserted (traverse in the pinecone_titles list and create the vector for each project. This will not take the last embedding vector as it is the final description of the candidate)
        description_vector = [{"id": title, "values": embeddings[i],
                               'metadata': metadatas[i]} for i, title in enumerate(pinecone_titles)]
        # Upsert the vector to the Pinecone database
        self.__upsert_to_database(namespace, description_vector)

        # UPSERTING THE FINAL DESCRIPTION OF THE CANDIDATE TO THE DATABASE
        # Extract the namespace from the Pinecone configuration and create the vector to be upserted
        cand_desc_namespace = self.__pinecone_config['candidate_description_namespace']
        gen_desc_vec = [{"id": f"{candidate_id}", "values": embeddings[-1]}]
        # Upsert the vector to the Pinecone database
        self.__upsert_to_database(cand_desc_namespace, gen_desc_vec)

        return cand_final_desc

    def delete_candidate(self, data):
        """
        This function can be called to delete a candidate from the database.

        It takes the raw data of the candidate and:
        1. extracts the project names and combines them with the candidate's id to get the vector ids to be deleted,
        2. deletes the project vector ids from the Pinecone database, and
        3. deletes the description of the candidate from the Pinecone database.

        Parameters
        ----------
        data : dict
            A dictionary containing the raw data of the candidate.
            The dictionary should contain the following
            - id (str): The unique identifier of the candidate.
            - projects (list): The list of titles of the candidate's projects.

        Returns
        -------
        None
        """
        # Set the raw data of the candidate
        self.data = data

        # Create an instance of the Pinecone Index
        index = self.__pc.Index(self.__pinecone_config['index_name'])

        # Define the vector ids to be deleted and the namespace of the final descriptions
        # creating list as pinecone delete function takes list of ids
        ids = [str(self.data['id'])]
        namespace = self.__pinecone_config['candidate_description_namespace']
        # Delete the final description of the candidate from the Pinecone database
        index.delete(ids=ids, namespace=namespace)

        # Get the projects of the candidate
        projects = self.data['projects']

        # Define the vector ids to be deleted and the namespace of the projects
        ids = [f"{self.data['id']}__{project}" for project in projects]
        namespace = self.__pinecone_config['projects_namespace']
        # Delete the projects of the candidate from the Pinecone database
        index.delete(ids=ids, namespace=namespace)

        return

    def delete_jdk(self, data):
        """
        This function can be called to delete a job description from the database.

        It takes the raw data of the job description and:
        1. deletes the vector id of the job description from the Pinecone database.

        Parameters
        ----------
        data : dict
            A dictionary containing the raw data of the job description.
            The dictionary should contain the following
            - id (str): The unique identifier of the job description.

        Returns
        -------
        None
        """
        # Set the raw data of the job description
        self.data = data

        # Create an instance of the Pinecone Index
        index = self.__pc.Index(self.__pinecone_config['index_name'])

        # creating list as pinecone delete function takes list of ids
        ids = [str(self.data['id'])]
        namespace = self.__pinecone_config['jdk_namespace']
        # Delete the job description from the Pinecone database
        index.delete(ids=ids, namespace=namespace)

        return
